{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467021cd-e075-4e12-99d5-f1290dcc50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mygene\n",
    "import os\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Opt into the future behavior for silent downcasting\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e8f675-383d-4c25-a39f-126a75b6f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gene_ids_and_symbols(df):\n",
    "\n",
    "    ## Make a copy to use in function\n",
    "    dff = df.copy()\n",
    "    \n",
    "    ## Get all the unique gene_id and gene_symbols\n",
    "    df_ids = dff[\"gene_id\"].copy().drop_duplicates(inplace=False).dropna(inplace=False).to_list()\n",
    "    df_symbols = dff[\"gene_symbol\"].copy().drop_duplicates(inplace=False).dropna(inplace=False).to_list()\n",
    "\n",
    "    ## Query by gene_ids and gene_symbols\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    results_id_query = mg.querymany(df_ids, scopes='symbol,alias,name,ensembl.gene,ensembl.transcript', fields='symbol,ensembl.gene', species='human', as_dataframe=True, df_index=False, returnall=False)\n",
    "    results_symbol_query = mg.querymany(df_symbols, scopes='symbol,alias,name,ensembl.gene,ensembl.transcript', fields='symbol,ensembl.gene', species='human', as_dataframe=True, df_index=False, returnall=False)\n",
    "    \n",
    "    ## Delete duplicates, only keep highest value\n",
    "    results_id_query = results_id_query.sort_values(by=['query', '_score'], ascending=[True, False]).drop_duplicates(subset='query', keep='first')\n",
    "    results_symbol_query = results_symbol_query.sort_values(by=['query', '_score'], ascending=[True, False]).drop_duplicates(subset='query', keep='first')\n",
    "    \n",
    "    # Ensure that the column 'ensembl' is of string type, which allows the use of string methods\n",
    "    results_id_query[\"ensembl\"] = results_id_query[\"ensembl\"].astype(str)\n",
    "    results_symbol_query[\"ensembl\"] = results_symbol_query[\"ensembl\"].astype(str)\n",
    "    \n",
    "    # Split the strings and handle NaNs by chaining the .str methods\n",
    "    results_id_query[\"first_ensembl\"] = results_id_query[\"ensembl\"].str.split(\":\", expand=True)[1].str.split(\"'\", expand=True)[1]\n",
    "    results_symbol_query[\"first_ensembl\"] = results_symbol_query[\"ensembl\"].str.split(\":\", expand=True)[1].str.split(\"'\", expand=True)[1]\n",
    "\n",
    "    # Standardize all NaN-like values to pd.NA\n",
    "    results_id_query = results_id_query.replace({np.nan: pd.NA, None: pd.NA, \"nan\": pd.NA})\n",
    "    results_symbol_query = results_symbol_query.replace({np.nan: pd.NA, None: pd.NA, \"nan\": pd.NA})\n",
    "    \n",
    "    # Fill NA values in 'ensembl.gene' column with values from 'first_ensembl' column\n",
    "    results_id_query['ensembl.gene'] = results_id_query['ensembl.gene'].copy().fillna(results_id_query['first_ensembl'], inplace=False)\n",
    "    results_symbol_query['ensembl.gene'] = results_symbol_query['ensembl.gene'].copy().fillna(results_symbol_query['first_ensembl'], inplace=False)\n",
    "\n",
    "    ## Only keep relevant columns\n",
    "    results_id_query = results_id_query[[\"query\", \"ensembl.gene\", \"symbol\"]].copy()\n",
    "    results_symbol_query = results_symbol_query[[\"query\", \"ensembl.gene\", \"symbol\"]].copy()\n",
    "\n",
    "    ## Rename columns\n",
    "    results_id_query.columns = [\"gene_id\", \"from_id_ensembl_id\", \"from_id_official_gene_symbol\"]\n",
    "    results_symbol_query.columns = [\"gene_symbol\", \"from_symbol_ensembl_id\", \"from_symbol_official_gene_symbol\"]\n",
    "\n",
    "    results_id_query.drop_duplicates(inplace=True)\n",
    "    results_symbol_query.drop_duplicates(inplace=True)\n",
    "\n",
    "    \n",
    "    ## Merge with original dataframe\n",
    "    dff = dff.merge(results_id_query, how=\"left\", on=\"gene_id\")\n",
    "    dff = dff.merge(results_symbol_query, how=\"left\", on=\"gene_symbol\")\n",
    "\n",
    "    ## Combine results from both approaches (symbol and id)\n",
    "    dff['ensembl_id'] = dff['from_id_ensembl_id'].copy().fillna(dff['from_symbol_ensembl_id'], inplace=False)\n",
    "    dff['official_symbol'] = dff['from_id_official_gene_symbol'].copy().fillna(dff['from_symbol_official_gene_symbol'], inplace=False)\n",
    "\n",
    "    ## Drop intermediate columns\n",
    "    dff.drop(columns=[\"from_id_ensembl_id\", \"from_id_official_gene_symbol\", \"from_symbol_ensembl_id\", \"from_symbol_official_gene_symbol\", \"gene_id\", \"gene_symbol\"], inplace=True)\n",
    "\n",
    "    ## Drop anything that is missing both ensembl_id and official_symbol. Also drop any duplicates\n",
    "    dff.dropna(subset=[\"ensembl_id\", \"official_symbol\"], how=\"all\", inplace=True)\n",
    "    \n",
    "    ## Drop Duplicates\n",
    "    dff.drop_duplicates(inplace=True)\n",
    "    dff.drop_duplicates(subset=[\"ensembl_id\", \"official_symbol\"], inplace=True)\n",
    "\n",
    "    \n",
    "    ## Make ensembl id and official symbol the first two columns \n",
    "    dff = dff[dff.columns[-2:].tolist() + dff.columns[:-2].tolist()].copy()\n",
    "\n",
    "    \n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15323d60-e44b-4037-8712-1f4b3551b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file names: miller_et_al_parietal_white_matter.csv \n",
      "\n",
      "Opening file names: das_et_al_plaque_vs_control.csv \n",
      "\n",
      "Opening file names: king_et_al_BA17_synaptoneurosome.csv \n",
      "\n",
      "Opening file names: miller_et_al_temporal_cortex.csv \n",
      "\n",
      "Opening file names: das_et_al_tangle_vs_control.csv \n",
      "\n",
      "Opening file names: king_et_al_BA17_total_brain_homogenate.csv \n",
      "\n",
      "Opening file names: fischer_et_al.csv \n",
      "\n",
      "Opening file names: felsky_et_al.csv \n",
      "\n",
      "Opening file names: miller_et_al_parietal_cortex.csv \n",
      "\n",
      "Opening file names: miller_et_al_hippocampus.csv \n",
      "\n",
      "Opening file names: das_et_al_peri-plaque_vs_control.csv \n",
      "\n",
      "Opening file names: van_rooij_et_al.csv \n",
      "\n",
      "Opening file names: das_et_al_distant_vs_control.csv \n",
      "\n",
      "Opening file names: king_et_al_BA20_synaptoneurosome.csv \n",
      "\n",
      "Opening file names: king_et_al_BA20_total_brain_homogenate.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = '../../data/raw_data/meta-analysis/'\n",
    "\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        ## Print filename for records\n",
    "        print(\"Opening file names:\", filename,\"\\n\")\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        ## Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        ## Append the dataframe to the list\n",
    "        dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897500bc-eb95-4226-97c6-421eae3a2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix column names manually\n",
    "\n",
    "dataframes[0].columns = ['gene_symbol', 'AD vs Control: Parietal White Matter - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: White Matter - SVA P-value -  RIN corrected']\n",
    "      \n",
    "dataframes[1].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "      \n",
    "dataframes[2].columns = ['gene_id', 'gene_symbol', 'BA17_SNp_HA_vs_AD.l2fc', 'BA17_SNp_HA_vs_AD.pval',\n",
    "       'BA17_SNp_HA_vs_AD.padj', 'BA17_SNp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
    "      \n",
    "dataframes[3].columns = ['gene_symbol', 'AD vs Control: Temporal Cortex - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: Temporal Cortex - SVA P-value -  RIN corrected',\n",
    "       'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n",
    "      \n",
    "dataframes[4].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "      \n",
    "dataframes[5].columns = ['gene_id', 'gene_symbol', 'BA17_THp_HA_vs_AD.l2fc', 'BA17_THp_HA_vs_AD.pval',\n",
    "       'BA17_THp_HA_vs_AD.padj', 'BA17_THp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
    "      \n",
    "dataframes[6].columns = ['gene_id', 'entrez_id', 'gene_symbol', 'logFC', 'AveExpr', 't', 'P.Value',\n",
    "       'adj.P.Val']\n",
    "      \n",
    "dataframes[7].columns = ['gene_id', 'gene_symbol', 'logFC', 'AveExpr', 't', 'P.Value', 'adj.P.Val', 'B',\n",
    "       'se', 'chr', 'N']\n",
    "      \n",
    "dataframes[8].columns = ['gene_symbol', 'AD vs Control: Parietal Cortex - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: Parietal Cortex - SVA P-value -  RIN corrected']\n",
    "      \n",
    "dataframes[9].columns = ['gene_symbol', 'AD vs Control: Hippocampus - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: Hippocampus - SVA P-value -  RIN corrected']\n",
    "      \n",
    "dataframes[10].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "      \n",
    "dataframes[11].columns = ['gene_symbol', 'logFC', 'logCPM', 'PValue', 'FDR', 'UP/DOWN', 'DE Score']\n",
    "\n",
    "dataframes[12].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "\n",
    "dataframes[13].columns = ['gene_id', 'gene_symbol', 'BA20_SNp_HA_vs_AD.l2fc', 'BA20_SNp_HA_vs_AD.pval',\n",
    "       'BA20_SNp_HA_vs_AD.padj', 'BA20_SNp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
    "\n",
    "dataframes[14].columns = ['gene_id', 'gene_symbol', 'BA20_THp_HA_vs_AD.l2fc', 'BA20_THp_HA_vs_AD.pval',\n",
    "       'BA20_THp_HA_vs_AD.padj', 'BA20_THp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf4bda7-912e-4ac7-9515-c1e113b60c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unnamed columns\n",
    "\n",
    "for df in dataframes:\n",
    "    df.drop(columns=[col for col in df.columns if col.startswith('Unnamed:')], inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382669e9-c8c2-4a76-b5dc-9ca63fff9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the relevant columns\n",
    "\n",
    "dataframes[0] = dataframes[0][['gene_symbol', 'AD vs Control: Parietal White Matter - Log2(fold change) - RIN Corrected',\n",
    "                'AD vs Control: White Matter - SVA P-value -  RIN corrected']].copy()\n",
    "dataframes[0].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[1] = dataframes[1][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[1].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[2] = dataframes[2][['gene_id', 'gene_symbol', 'BA17_SNp_HA_vs_AD.l2fc', 'BA17_SNp_HA_vs_AD.pval']].copy()\n",
    "dataframes[2].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[3] = dataframes[3][['gene_symbol', 'AD vs Control: Temporal Cortex - Log2(fold change) - RIN Corrected',\n",
    "                               'AD vs Control: Temporal Cortex - SVA P-value -  RIN corrected']]\n",
    "dataframes[3].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[4] = dataframes[4][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[4].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[5] = dataframes[5][['gene_id', 'gene_symbol', 'BA17_THp_HA_vs_AD.l2fc', 'BA17_THp_HA_vs_AD.pval']].copy()\n",
    "dataframes[5].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[6] = dataframes[6][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[6].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[7] = dataframes[7][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[7].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[8] = dataframes[8][['gene_symbol', 'AD vs Control: Parietal Cortex - Log2(fold change) - RIN Corrected',\n",
    "               'AD vs Control: Parietal Cortex - SVA P-value -  RIN corrected']].copy()\n",
    "dataframes[8].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[9] = dataframes[9][['gene_symbol', 'AD vs Control: Hippocampus - Log2(fold change) - RIN Corrected',\n",
    "                'AD vs Control: Hippocampus - SVA P-value -  RIN corrected']].copy()\n",
    "dataframes[9].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[10] = dataframes[10][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[10].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[11] = dataframes[11][['gene_symbol', 'logFC',  'PValue']].copy()\n",
    "dataframes[11].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[12] = dataframes[12][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[12].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[13] = dataframes[13][['gene_id', 'gene_symbol', 'BA20_SNp_HA_vs_AD.l2fc', 'BA20_SNp_HA_vs_AD.pval']].copy()\n",
    "dataframes[13].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[14] = dataframes[14][['gene_id', 'gene_symbol', 'BA20_THp_HA_vs_AD.l2fc', 'BA20_THp_HA_vs_AD.pval']].copy()\n",
    "dataframes[14].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85ff416-d366-4e11-a0b4-49bef9d315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize counter\n",
    "i=0\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "    \n",
    "    ## Standardize missing values\n",
    "    df = df.replace({np.nan: pd.NA, None: pd.NA})\n",
    "    \n",
    "    if \"gene_id\" in df.columns:\n",
    "        ## Take out . from ensembl ids\n",
    "        df[\"gene_id\"] = df[\"gene_id\"].str.split(\".\", expand=True)[0]\n",
    "        ## Set gene ids that are not ensembl IDs to NA\n",
    "        df['gene_id'] = df['gene_id'].apply(lambda x: x if pd.isna(x) or str(x).startswith('ENS') else pd.NA)\n",
    "\n",
    "    # Check if 'gene_symbol' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_symbol' not in df.columns:\n",
    "        df['gene_symbol'] = df['gene_id'].copy()\n",
    "\n",
    "    # Check if 'ensembl_id' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_id' not in df.columns:\n",
    "        df['gene_id'] = df['gene_symbol'].copy()\n",
    "\n",
    "    # Ensure 'ensembl_id' is the first column and 'gene_symbol' is the second column\n",
    "    columns = ['gene_id', 'gene_symbol'] + [col for col in df.columns if col not in ['gene_id', 'gene_symbol']]\n",
    "    df = df[columns].copy()\n",
    "    dataframes[i] = df\n",
    "\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df3566a-5b99-4695-8628-1cbbed1e5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n",
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65 input query terms found no hit:\t['ENSG00000270168', 'ENSG00000257151', 'ENSG00000221995', 'ENSG00000237548', 'ENSG00000243444', 'ENS\n",
      "4365 input query terms found dup hits:\t[('SPN', 3), ('ITGB2', 2), ('KLHL6', 3), ('PIK3R5', 3), ('LILRA2', 3), ('NCF2', 2), ('LILRB1', 4), (\n",
      "772 input query terms found no hit:\t['AC116667.1', 'AC119674.1', 'AL683813.1', 'AC145285.2', 'AC108062.1', 'AL121672.1', 'AL355974.2', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 input query terms found dup hits:\t[('ENSG00000249738', 2), ('ENSG00000230373', 2), ('ENSG00000278903', 3), ('ENSG00000188660', 2), ('E\n",
      "401 input query terms found no hit:\t['ENSG00000228106', 'ENSG00000259834', 'ENSG00000272301', 'ENSG00000267034', 'ENSG00000261409', 'ENS\n",
      "11480 input query terms found dup hits:\t[('DPP10', 5), ('C1QTNF1', 3), ('SPIN1', 2), ('CORO7', 2), ('OXR1', 4), ('KCNIP4', 2), ('RASA1', 2),\n",
      "19840 input query terms found no hit:\t['AC079834.2', 'AC090578.1', 'AL139125.1', 'AC104083.1', 'AC015712.2', 'AC124804.1', 'AC104024.2', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n",
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65 input query terms found no hit:\t['ENSG00000270168', 'ENSG00000204092', 'ENSG00000221995', 'ENSG00000237548', 'ENSG00000257151', 'ENS\n",
      "4365 input query terms found dup hits:\t[('UCKL1', 2), ('DDIT4', 2), ('PSMA5', 2), ('STAT1', 2), ('FXYD2', 2), ('KANSL1', 2), ('GTF2IRD1', 2\n",
      "772 input query terms found no hit:\t['AC119674.1', 'AC018557.2', 'AL121672.1', 'AF064858.1', 'AC000403.1', 'AC010618.3', 'AP001043.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 input query terms found dup hits:\t[('ENSG00000249738', 2), ('ENSG00000230373', 2), ('ENSG00000278903', 3), ('ENSG00000188660', 2), ('E\n",
      "401 input query terms found no hit:\t['ENSG00000228106', 'ENSG00000259834', 'ENSG00000272301', 'ENSG00000267034', 'ENSG00000261409', 'ENS\n",
      "11480 input query terms found dup hits:\t[('DPP10', 5), ('C1QTNF1', 3), ('SPIN1', 2), ('CORO7', 2), ('OXR1', 4), ('KCNIP4', 2), ('RASA1', 2),\n",
      "19840 input query terms found no hit:\t['AC079834.2', 'AC090578.1', 'AL139125.1', 'AC104083.1', 'AC015712.2', 'AC124804.1', 'AC104024.2', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 input query terms found no hit:\t['ENSG00000228439', 'ENSG00000270672', 'ENSG00000213865', 'ENSG00000189144', 'ENSG00000180525', 'ENS\n",
      "3646 input query terms found dup hits:\t[('ITGB8', 2), ('MKLN1', 3), ('STAG1', 3), ('MPI', 2), ('LIFR', 2), ('SP3', 4), ('PKN2', 2), ('FKBP1\n",
      "20 input query terms found no hit:\t['8-Mar', '4-Mar', '10-Sep', '4-Sep', '9-Mar', '3-Mar', '2-Mar', 'LOC102724488', '1-Sep', '6-Sep', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 input query terms found dup hits:\t[('ENSG00000230373', 2)]\n",
      "124 input query terms found no hit:\t['ENSG00000213240', 'ENSG00000263013', 'ENSG00000187695', 'ENSG00000189144', 'ENSG00000261490', 'ENS\n",
      "4688 input query terms found dup hits:\t[('DUSP5', 3), ('GABPB1', 5), ('GEM', 10), ('BACE2', 3), ('FREM2', 3), ('GRTP1', 3), ('LINC00598', 2\n",
      "1586 input query terms found no hit:\t['AC025257.1', 'AP002884.1', 'AC104162.1', 'AL137003.2', 'AC092807.3', 'AC139713.2', 'AC016026.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n",
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n",
      "5030 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA11P', 2), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10)\n",
      "1750 input query terms found no hit:\t['CRIPAK', 'ERCC6-PGBD3', 'FAM231D', 'FBXO22-AS1', 'FLJ10038', 'FLJ23867', 'FLJ27354', 'FLJ31104', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65 input query terms found no hit:\t['ENSG00000180525', 'ENSG00000270168', 'ENSG00000257151', 'ENSG00000256427', 'ENSG00000237548', 'ENS\n",
      "4365 input query terms found dup hits:\t[('DDIT4', 2), ('FOXD1', 3), ('LINC00484', 2), ('NRSN2', 2), ('IDI1', 7), ('DPY19L1', 6), ('UCKL1', \n",
      "772 input query terms found no hit:\t['AC117500.2', 'AC010618.3', 'AC119674.1', 'AC116667.1', 'AC102953.2', 'AC145285.2', 'AC108062.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3990 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10), ('ABCC3', 2), \n",
      "121 input query terms found no hit:\t['AC002472.13', 'AC004381.6', 'AC005003.1', 'AC006547.14', 'AC006946.15', 'AC007375.1', 'AC007390.5'\n",
      "3990 input query terms found dup hits:\t[('A2M', 4), ('A2ML1', 5), ('AARSD1', 3), ('ABCA3', 3), ('ABCA9', 2), ('ABCB10', 10), ('ABCC3', 2), \n",
      "121 input query terms found no hit:\t['AC002472.13', 'AC004381.6', 'AC005003.1', 'AC006547.14', 'AC006946.15', 'AC007375.1', 'AC007390.5'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65 input query terms found no hit:\t['ENSG00000259855', 'ENSG00000237548', 'ENSG00000273576', 'ENSG00000237721', 'ENSG00000230839', 'ENS\n",
      "4365 input query terms found dup hits:\t[('UCKL1', 2), ('LINC00484', 2), ('DDIT4', 2), ('FIBCD1', 3), ('IDI1', 7), ('EHMT1', 2), ('KANSL1', \n",
      "772 input query terms found no hit:\t['AC119674.1', 'AL121672.1', 'AC010618.3', 'AL583810.2', 'AP000808.1', 'AC092747.4', 'AL360012.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 input query terms found dup hits:\t[('ENSG00000249738', 2), ('ENSG00000230373', 2), ('ENSG00000278903', 3), ('ENSG00000188660', 2), ('E\n",
      "401 input query terms found no hit:\t['ENSG00000228106', 'ENSG00000259834', 'ENSG00000272301', 'ENSG00000267034', 'ENSG00000261409', 'ENS\n",
      "11480 input query terms found dup hits:\t[('DPP10', 5), ('C1QTNF1', 3), ('SPIN1', 2), ('CORO7', 2), ('OXR1', 4), ('KCNIP4', 2), ('RASA1', 2),\n",
      "19840 input query terms found no hit:\t['AC079834.2', 'AC090578.1', 'AL139125.1', 'AC104083.1', 'AC015712.2', 'AC124804.1', 'AC104024.2', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10 input query terms found dup hits:\t[('ENSG00000249738', 2), ('ENSG00000230373', 2), ('ENSG00000278903', 3), ('ENSG00000188660', 2), ('E\n",
      "401 input query terms found no hit:\t['ENSG00000228106', 'ENSG00000259834', 'ENSG00000272301', 'ENSG00000267034', 'ENSG00000261409', 'ENS\n",
      "11480 input query terms found dup hits:\t[('DPP10', 5), ('C1QTNF1', 3), ('SPIN1', 2), ('CORO7', 2), ('OXR1', 4), ('KCNIP4', 2), ('RASA1', 2),\n",
      "19840 input query terms found no hit:\t['AC079834.2', 'AC090578.1', 'AL139125.1', 'AC104083.1', 'AC015712.2', 'AC124804.1', 'AC104024.2', '\n"
     ]
    }
   ],
   "source": [
    "## Now standardize gene_symbol and gene_id for all the dataframes\n",
    "\n",
    "## Initialize counter\n",
    "i=0\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "\n",
    "    print(i)\n",
    "    ## Create master dataframe\n",
    "    master_df = unify_gene_ids_and_symbols(df)\n",
    "\n",
    "    ## Create column that is the official gene symbol, unless that is NA, then make it the ensembl_id\n",
    "    \n",
    "    # Check if 'gene_symbol' column is missing and add it filled with NAs if necessary\n",
    "    if 'official_symbol' not in df.columns:\n",
    "        df['official_symbol'] = \"NA_symbol\"\n",
    "\n",
    "    # Check if 'ensembl_id' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_id' not in df.columns:\n",
    "        df['gene_id'] = \"NA_id\"\n",
    "    \n",
    "    master_df['gene_name'] = master_df['official_symbol'].copy() + \"|\" + master_df['ensembl_id'].copy()\n",
    "\n",
    "    ## Make it the first column\n",
    "    master_df = master_df[master_df.columns[-1:].tolist() + master_df.columns[:-1].tolist()]\n",
    "\n",
    "    dataframes[i] = master_df\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a79d6a-79fd-43ca-87bf-5616f784f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get output file names\n",
    "output_names = [\"miller_et_al_parietal_white_matter_ad_vs_control_RIN_corrected_processed.tsv\", \n",
    "                \"das_et_al_superior_temporal_gyrus_ad_plaque_ad_vs_control.tsv\",\n",
    "                \"king_et_al_BA17_visual_cortex_synaptoneurosome_ad_vs_ha.tsv\", \n",
    "                \"miller_et_al_temporal_cortex_ad_vs_control_RIN_corrected_processed.tsv\",\n",
    "                \"das_et_al_superior_temporal_gyrus_ad_tangle_vs_control.tsv\", \n",
    "                \"king_et_al_BA17_visual_cortex_total_brain_homogenate_ad_vs_ha.tsv\",\n",
    "                \"fischer_et_al_prefrontal_cortex_ad_vs_control.tsv\", \n",
    "                \"felsky_et_al_temporal_cortex_ad_vs_control.tsv\", \n",
    "                \"miller_et_al_parietal_cortex_ad_vs_control_RIN_corrected_processed.tsv\",\n",
    "                \"miller_et_al_hippocampus_ad_vs_control_RIN_corrected_processed.tsv\", \n",
    "                \"das_et_al_superior_temporal_gyrus_ad_peri-plaque_vs_control.tsv\",\n",
    "                \"van_rooij_et_al_hippocampus_ad_vs_control.tsv\", \n",
    "                \"das_et_al_superior_temporal_gyrus_ad_distant_vs_control.tsv\",\n",
    "                \"king_et_al_BA20_temporal_cortex_synaptoneurosome_ad_vs_ha.tsv\",\n",
    "                \"king_et_al_BA20_temporal_cortex_total_brain_homogenate_ad_vs_ha.tsv\"]\n",
    "\n",
    "## Get sample sizes\n",
    "sample_sizes = [106, 18, 31, 106, 18 ,31, 29, 39, 106, 106, 18, 28, 18, 31 ,31]\n",
    "\n",
    "\n",
    "## Now add information and save\n",
    "\n",
    "## Initialize counter and output directory\n",
    "i=0\n",
    "output_dir = \"../../data/processed_data/meta-analysis/meta-analysis_input/\"\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "\n",
    "    dataframes[i] = dataframes[i][[\"gene_name\", \"log2_fold_change\", \"p_value\"]].copy()\n",
    "\n",
    "    ## Add sample sizes\n",
    "    dataframes[i][\"sample_size\"] = sample_sizes[i]\n",
    "    dataframes[i][\"ref_allele\"] = \"Control\"\n",
    "    dataframes[i][\"non_ref_allele\"] = \"AD\"\n",
    "\n",
    "    ## Create output path\n",
    "    output_path = output_dir + output_names[i]\n",
    "\n",
    "    dataframes[i].to_csv(output_path, index=False, sep=\"\\t\")\n",
    "\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
