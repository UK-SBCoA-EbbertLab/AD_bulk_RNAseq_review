{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467021cd-e075-4e12-99d5-f1290dcc50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mygene\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Opt into the future behavior for silent downcasting\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9e7a9b-95ef-442f-9d13-e94cfa9ae7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gene_ids_and_symbols(df):\n",
    "\n",
    "    ## Make a copy to use in function\n",
    "    dff = df.copy()\n",
    "    \n",
    "    ## Take out . from ensembl ids\n",
    "    dff[\"gene_id\"] = dff[\"gene_id\"].str.split(\".\", expand=True)[0]\n",
    "\n",
    "    # Standardize all NaN-like values to pd.NA\n",
    "    dff = dff.replace({np.nan: pd.NA, None: pd.NA})\n",
    "\n",
    "    ## Set gene ids that are not ensembl IDs to NA\n",
    "    dff['gene_id'] = dff['gene_id'].apply(lambda x: x if pd.isna(x) or str(x).startswith('ENS') else pd.NA)\n",
    "\n",
    "    ## Get all the unique gene_id and gene_symbols\n",
    "    df_ids = dff[\"gene_id\"].copy().drop_duplicates(inplace=False).dropna(inplace=False).to_list()\n",
    "    df_symbols = dff[\"gene_symbol\"].copy().drop_duplicates(inplace=False).dropna(inplace=False).to_list()\n",
    "\n",
    "    ## Query by gene_ids and gene_symbols\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    results_id_query = mg.querymany(df_ids, scopes='symbol,alias,name,ensembl.gene,ensembl.transcript', fields='symbol,ensembl.gene', species='human', as_dataframe=True, df_index=False, returnall=False)\n",
    "    results_symbol_query = mg.querymany(df_symbols, scopes='symbol,alias,name,ensembl.gene,ensembl.transcript', fields='symbol,ensembl.gene', species='human', as_dataframe=True, df_index=False, returnall=False)\n",
    "\n",
    "    ## Delete duplicates, only keep highest value\n",
    "    results_id_query = results_id_query.sort_values(by=['query', '_score'], ascending=[True, False]).drop_duplicates(subset='query', keep='first')\n",
    "    results_symbol_query = results_symbol_query.sort_values(by=['query', '_score'], ascending=[True, False]).drop_duplicates(subset='query', keep='first')\n",
    "    \n",
    "    # Ensure that the column 'ensembl' is of string type, which allows the use of string methods\n",
    "    results_id_query[\"ensembl\"] = results_id_query[\"ensembl\"].astype(str)\n",
    "    results_symbol_query[\"ensembl\"] = results_symbol_query[\"ensembl\"].astype(str)\n",
    "    \n",
    "    # Split the strings and handle NaNs by chaining the .str methods\n",
    "    results_id_query[\"first_ensembl\"] = results_id_query[\"ensembl\"].str.split(\":\", expand=True)[1].str.split(\"'\", expand=True)[1]\n",
    "    results_symbol_query[\"first_ensembl\"] = results_symbol_query[\"ensembl\"].str.split(\":\", expand=True)[1].str.split(\"'\", expand=True)[1]\n",
    "\n",
    "    \n",
    "    # Standardize all NaN-like values to pd.NA\n",
    "    results_id_query = results_id_query.replace({np.nan: pd.NA, None: pd.NA, \"nan\": pd.NA})\n",
    "    results_symbol_query = results_symbol_query.replace({np.nan: pd.NA, None: pd.NA, \"nan\": pd.NA})\n",
    "    \n",
    "    # Fill NA values in 'ensembl.gene' column with values from 'first_ensembl' column\n",
    "    results_id_query['ensembl.gene'] = results_id_query['ensembl.gene'].copy().fillna(results_id_query['first_ensembl'], inplace=False)\n",
    "    results_symbol_query['ensembl.gene'] = results_symbol_query['ensembl.gene'].copy().fillna(results_symbol_query['first_ensembl'], inplace=False)\n",
    "\n",
    "    ## Only keep relevant columns\n",
    "    results_id_query = results_id_query[[\"query\", \"ensembl.gene\", \"symbol\"]].copy()\n",
    "    results_symbol_query = results_symbol_query[[\"query\", \"ensembl.gene\", \"symbol\"]].copy()\n",
    "\n",
    "    ## Rename columns\n",
    "    results_id_query.columns = [\"gene_id\", \"from_id_ensembl_id\", \"from_id_official_gene_symbol\"]\n",
    "    results_symbol_query.columns = [\"gene_symbol\", \"from_symbol_ensembl_id\", \"from_symbol_official_gene_symbol\"]\n",
    "\n",
    "    results_id_query.drop_duplicates(inplace=True)\n",
    "    results_symbol_query.drop_duplicates(inplace=True)\n",
    "\n",
    "    \n",
    "    ## Merge with original dataframe\n",
    "    dff = dff.merge(results_id_query, how=\"left\", on=\"gene_id\")\n",
    "    dff = dff.merge(results_symbol_query, how=\"left\", on=\"gene_symbol\")\n",
    "\n",
    "    ## Combine results from both approaches (symbol and id)\n",
    "    dff['ensembl_id'] = dff['from_id_ensembl_id'].copy().fillna(dff['from_symbol_ensembl_id'], inplace=False)\n",
    "    dff['official_symbol'] = dff['from_id_official_gene_symbol'].copy().fillna(dff['from_symbol_official_gene_symbol'], inplace=False)\n",
    "\n",
    "    ## Drop intermediate columns\n",
    "    dff.drop(columns=[\"from_id_ensembl_id\", \"from_id_official_gene_symbol\", \"from_symbol_ensembl_id\", \"from_symbol_official_gene_symbol\", \"gene_id\", \"gene_symbol\"], inplace=True)\n",
    "\n",
    "    ## Drop anything that is missing both ensembl_id and official_symbol\n",
    "    dff.dropna(subset=[\"ensembl_id\", \"official_symbol\"], how=\"all\", inplace=True)\n",
    "    \n",
    "    ## Drop Duplicates\n",
    "    dff.drop_duplicates(inplace=True)\n",
    "    \n",
    "    ## Make ensembl id and official symbol the first two columns \n",
    "    dff = dff[dff.columns[-2:].tolist() + dff.columns[:-2].tolist()].copy()\n",
    "\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a11e25-6193-4f49-889a-b35993da3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data\n",
    "df = pd.read_csv(\"../../data/raw_data/overlap_analysis/all_studies_ad_vs_healthy_control_DEG_overlap.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9428020f-f1c7-4fd8-9cd2-6eae00a1370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 17 studies to begin with\n"
     ]
    }
   ],
   "source": [
    "## Show how many studies we began with\n",
    "print(\"There were\", str(df[\"study\"].nunique()), \"studies to begin with\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878f883b-9256-4271-a4ca-0cf4b1de722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study Annese et al. was removed because the its quality score was below or at 1.5\n",
      "There were 16 studies left after filtering out those with quality score <= 1.5\n"
     ]
    }
   ],
   "source": [
    "## Drop all studies with quality score less than or equal to 1.5\n",
    "print(\"The study\", str(df.loc[df[\"quality_assessment\"] > 1.5][\"study\"].unique()[0]), \"was removed because the its quality score was below or at 1.5\")\n",
    "\n",
    "df = df.loc[df[\"quality_assessment\"] > 1.5].copy()\n",
    "\n",
    "print(\"There were\", str(df[\"study\"].nunique()), \"studies left after filtering out those with quality score <= 1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a04e12-15ff-4152-ae0c-d4dcd9f6252e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The study Lee et al. was removed because the brain region 'Cortex Tissues' was not specific enough\n",
      "\n",
      "The primary visual cortex data from study Guennewig et al. was removed because the brain region 'visual cortex' was only represented in one study\n",
      "\n",
      "The Entorhinal Cortex data from study Jia et al. was removed because the brain region 'visual cortex' was only represented in one study\n",
      "\n",
      "There were 14 studies left after filtering out the brain regions represented in only one study\n"
     ]
    }
   ],
   "source": [
    "## Remove under represented brain regions or brain regions that were not specified well\n",
    "print(\"The study\", str(df.loc[df[\"brain_region\"]==\"Cortex tissues\"][\"study\"].unique()[0]), \"was removed because the brain region 'Cortex Tissues' was not specific enough\")\n",
    "print(\"\\nThe primary visual cortex data from study\", str(df.loc[df[\"brain_region\"]==\"primary visual cortex\"][\"study\"].unique()[0]), \"was removed because the brain region 'visual cortex' was only represented in one study\")\n",
    "print(\"\\nThe Entorhinal Cortex data from study\", str(df.loc[df[\"brain_region\"]==\"Entorhinal Cortex\"][\"study\"].unique()[0]), \"was removed because the brain region 'visual cortex' was only represented in one study\")\n",
    "\n",
    "df = df.loc[df[\"brain_region\"] != \"Cortex tissues\"].copy()\n",
    "df = df.loc[df[\"brain_region\"] != \"primary visual cortex\"].copy()\n",
    "df = df.loc[df[\"brain_region\"] != \"Entorhinal Cortex\"].copy()\n",
    "\n",
    "print(\"\\nThere were\", str(df[\"study\"].nunique()), \"studies left after filtering out the brain regions represented in only one study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e51232-76cb-4fe1-ac29-ba9ead2d23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add specifier to some of the data from the isoform usage paper\n",
    "\n",
    "df.loc[df[\"brain_region\"] == \"Temporal Lobe (MAYO)\", \"study\"] = df[\"study\"] + \" (MAYO)\"\n",
    "df.loc[df[\"brain_region\"] == \"Frontal Lobe (MSSB BA10)\", \"study\"] = df[\"study\"] + \" (MSSB BA10)\"\n",
    "df.loc[df[\"brain_region\"] == \"Temporal Lobe (MSSB BA22)\", \"study\"] = df[\"study\"] + \" (MSSB BA22)\"\n",
    "df.loc[df[\"brain_region\"] == \"Temporal Lobe (MSSB BA36)\", \"study\"] = df[\"study\"] + \" (MSSB BA36)\"\n",
    "df.loc[df[\"brain_region\"] == \"Frontal Lobe (MSBB BA44)\", \"study\"] = df[\"study\"] + \" (MSSB BA44)\"\n",
    "df.loc[df[\"brain_region\"] == \"Frontal Lobe (ROSMAP)\", \"study\"] = df[\"study\"] + \" (ROSMAP)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ef59cf-f5e2-4083-ade6-5c53b4793bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the names\n",
    "\n",
    "df['brain_region'] = df['brain_region'].replace({'hippocampal CA1 region': 'Hippocampus', \"anterior temporal lobe\\xa0\": \"Temporal Lobe\", \"superior temporal gyrus\": \"Temporal Lobe\",\n",
    "                           \"temporal cortex\": \"Temporal Lobe\", 'prefrontal cortex': \"Frontal Lobe\", \"precuneus\": \"Parietal Lobe\", \"Temporal Cortex (BA20)\": \"Temporal Lobe\",\n",
    "                           \"Temporal Lobe (Superior Temporal Lobe)\": \"Temporal Lobe\", \"Temporal Lobe (MAYO)\": \"Temporal Lobe\", \"Frontal Lobe (MSSB BA10)\": \"Frontal Lobe\",\n",
    "                           'Temporal Lobe (MSSB BA22)': \"Temporal Lobe\", 'Temporal Lobe (MSSB BA36)': \"Temporal Lobe\", 'Frontal Lobe (MSBB BA44)': \"Frontal Lobe\", 'Frontal Lobe (ROSMAP)': \"Frontal Lobe\",\n",
    "                           'Frontal Lobe (Dorsolateral pre-frontal cortex)': \"Frontal Lobe\", 'Middle temporal gyrus': \"Temporal Lobe\",\n",
    "                           'Hippocampus (dentate gyrus and cornu amonis)': \"Hippocampus\", \"superior temporal gyrus \": \"Temporal Lobe\"}, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45039bd0-4482-4175-ac5a-14ecc3186d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 input query terms found dup hits:\t[('ENSG00000230373', 2)]\n",
      "267 input query terms found no hit:\t['ENSG00000231865', 'ENSG00000268759', 'ENSG00000197846', 'ENSG00000176034', 'ENSG00000264868', 'ENS\n",
      "3495 input query terms found dup hits:\t[('CYCS', 10), ('GPCPD1', 3), ('PRICKLE2', 7), ('PITPNA', 2), ('WDR7', 3), ('FARSA', 2), ('YPEL5', 8\n",
      "1825 input query terms found no hit:\t['KIAA1045', 'LOC100652824chr2:202937977-203061886', 'gen-01', 'LOC728730', '45355', 'LOC283070', 'L\n"
     ]
    }
   ],
   "source": [
    "## Create master dataframe\n",
    "master_df = unify_gene_ids_and_symbols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe9cef9-4c56-464f-b613-1c348546f709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We lost 724 entries due to not finding a gene_name or gene_id in the database\n"
     ]
    }
   ],
   "source": [
    "## Number of entries lost due to not finding gene_name or gene_id in the database\n",
    "print(\"We lost\", str(df.shape[0] - master_df.shape[0]), \"entries due to not finding a gene_name or gene_id in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08262da-3958-428a-a25a-b6d2b1a3c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create column that is the official gene symbol, unless that is NA, then make it the ensembl_id\n",
    "master_df['gene_name'] = master_df['official_symbol'].fillna(master_df['ensembl_id']).copy()\n",
    "\n",
    "## Make it the first column\n",
    "master_df = master_df[master_df.columns[-1:].tolist() + master_df.columns[:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bf57d7-1ad6-4a65-89ab-fbc471728203",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace all the spaces with underscores in the study column to make it easier to save later\n",
    "master_df['study'] = master_df['study'].str.replace(' ', '_')\n",
    "master_df['study'] = master_df['study'].str.replace('.', '')\n",
    "master_df['study'] = master_df['study'].str.replace('(', '')\n",
    "master_df['study'] = master_df['study'].str.replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff30566-3300-4bf2-a482-887530fc6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate by study and brain region\n",
    "\n",
    "df_temporal = master_df.loc[master_df[\"brain_region\"] == \"Temporal Lobe\"].copy()\n",
    "\n",
    "df_parietal = master_df.loc[master_df[\"brain_region\"] == \"Parietal Lobe\"].copy()\n",
    "\n",
    "df_hippocampus = master_df.loc[master_df[\"brain_region\"] == \"Hippocampus\"].copy()\n",
    "\n",
    "df_frontal = master_df.loc[master_df[\"brain_region\"] == \"Frontal Lobe\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5786e14f-9f05-4596-814e-068306d8b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate them by study\n",
    "\n",
    "temporal_studies = {study: df_temporal[df_temporal['study'] == study] for study in df_temporal['study'].unique()}\n",
    "\n",
    "parietal_studies = {study: df_parietal[df_parietal['study'] == study] for study in df_parietal['study'].unique()}\n",
    "\n",
    "hippocampus_studies = {study: df_hippocampus[df_hippocampus['study'] == study] for study in df_hippocampus['study'].unique()}\n",
    "\n",
    "frontal_studies = {study: df_frontal[df_frontal['study'] == study] for study in df_frontal['study'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868649c5-ce18-499c-8142-672efccd1df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Separate each brain region by study and save it into a CSV file for each study + brain region combo\n",
    "\n",
    "{df_temporal[df_temporal['study'] == study].to_csv(f\"../../data/processed_data/overlap_analysis/overlap_analysis_input/{study}_temporal_lobe.csv\", index=False) for study in df_temporal['study'].unique()}\n",
    "\n",
    "{df_parietal[df_parietal['study'] == study].to_csv(f\"../../data/processed_data/overlap_analysis/overlap_analysis_input/{study}_parietal_lobe.csv\", index=False) for study in df_parietal['study'].unique()}\n",
    "\n",
    "{df_hippocampus[df_hippocampus['study'] == study].to_csv(f\"../../data/processed_data/overlap_analysis/overlap_analysis_input/{study}_hippocampus.csv\", index=False) for study in df_hippocampus['study'].unique()}\n",
    "\n",
    "{df_frontal[df_frontal['study'] == study].to_csv(f\"../../data/processed_data/overlap_analysis/overlap_analysis_input/{study}_frontal_lobe.csv\", index=False) for study in df_frontal['study'].unique()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
