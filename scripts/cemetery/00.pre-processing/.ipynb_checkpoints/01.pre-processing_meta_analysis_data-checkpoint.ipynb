{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467021cd-e075-4e12-99d5-f1290dcc50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mygene\n",
    "import os\n",
    "\n",
    "## Display all rows of pandas dataframes\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Opt into the future behavior for silent downcasting\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e8f675-383d-4c25-a39f-126a75b6f0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_gene_ids_and_symbols(df):\n",
    "\n",
    "    ## Make a copy to use in function\n",
    "    dff = df.copy()\n",
    "    \n",
    "    ## Get all the unique gene_id and gene_symbols\n",
    "    df_ids = dff[\"gene_id\"].copy().drop_duplicates(inplace=False).dropna(inplace=False).to_list()\n",
    "    df_symbols = dff[\"gene_symbol\"].copy().drop_duplicates(inplace=False).dropna(inplace=False).to_list()\n",
    "\n",
    "    ## Query by gene_ids and gene_symbols\n",
    "    mg = mygene.MyGeneInfo()\n",
    "    results_id_query = mg.querymany(df_ids, scopes='symbol,alias,name,ensembl.gene,ensembl.transcript', fields='symbol,ensembl.gene', species='human', as_dataframe=True, df_index=False, returnall=False)\n",
    "    results_symbol_query = mg.querymany(df_symbols, scopes='symbol,alias,name,ensembl.gene,ensembl.transcript', fields='symbol,ensembl.gene', species='human', as_dataframe=True, df_index=False, returnall=False)\n",
    "    \n",
    "    ## Delete duplicates, only keep highest value\n",
    "    results_id_query = results_id_query.sort_values(by=['query', '_score'], ascending=[True, False]).drop_duplicates(subset='query', keep='first')\n",
    "    results_symbol_query = results_symbol_query.sort_values(by=['query', '_score'], ascending=[True, False]).drop_duplicates(subset='query', keep='first')\n",
    "    \n",
    "    # Ensure that the column 'ensembl' is of string type, which allows the use of string methods\n",
    "    results_id_query[\"ensembl\"] = results_id_query[\"ensembl\"].astype(str)\n",
    "    results_symbol_query[\"ensembl\"] = results_symbol_query[\"ensembl\"].astype(str)\n",
    "    \n",
    "    # Split the strings and handle NaNs by chaining the .str methods\n",
    "    results_id_query[\"first_ensembl\"] = results_id_query[\"ensembl\"].str.split(\":\", expand=True)[1].str.split(\"'\", expand=True)[1]\n",
    "    results_symbol_query[\"first_ensembl\"] = results_symbol_query[\"ensembl\"].str.split(\":\", expand=True)[1].str.split(\"'\", expand=True)[1]\n",
    "\n",
    "    # Standardize all NaN-like values to pd.NA\n",
    "    results_id_query = results_id_query.replace({np.nan: pd.NA, None: pd.NA, \"nan\": pd.NA})\n",
    "    results_symbol_query = results_symbol_query.replace({np.nan: pd.NA, None: pd.NA, \"nan\": pd.NA})\n",
    "    \n",
    "    # Fill NA values in 'ensembl.gene' column with values from 'first_ensembl' column\n",
    "    results_id_query['ensembl.gene'] = results_id_query['ensembl.gene'].copy().fillna(results_id_query['first_ensembl'], inplace=False)\n",
    "    results_symbol_query['ensembl.gene'] = results_symbol_query['ensembl.gene'].copy().fillna(results_symbol_query['first_ensembl'], inplace=False)\n",
    "\n",
    "    ## Only keep relevant columns\n",
    "    results_id_query = results_id_query[[\"query\", \"ensembl.gene\", \"symbol\"]].copy()\n",
    "    results_symbol_query = results_symbol_query[[\"query\", \"ensembl.gene\", \"symbol\"]].copy()\n",
    "\n",
    "    ## Rename columns\n",
    "    results_id_query.columns = [\"gene_id\", \"from_id_ensembl_id\", \"from_id_official_gene_symbol\"]\n",
    "    results_symbol_query.columns = [\"gene_symbol\", \"from_symbol_ensembl_id\", \"from_symbol_official_gene_symbol\"]\n",
    "\n",
    "    results_id_query.drop_duplicates(inplace=True)\n",
    "    results_symbol_query.drop_duplicates(inplace=True)\n",
    "\n",
    "    \n",
    "    ## Merge with original dataframe\n",
    "    dff = dff.merge(results_id_query, how=\"left\", on=\"gene_id\")\n",
    "    dff = dff.merge(results_symbol_query, how=\"left\", on=\"gene_symbol\")\n",
    "\n",
    "    ## Combine results from both approaches (symbol and id)\n",
    "    dff['ensembl_id'] = dff['from_id_ensembl_id'].copy().fillna(dff['from_symbol_ensembl_id'], inplace=False)\n",
    "    dff['official_symbol'] = dff['from_id_official_gene_symbol'].copy().fillna(dff['from_symbol_official_gene_symbol'], inplace=False)\n",
    "\n",
    "    ## Drop intermediate columns\n",
    "    dff.drop(columns=[\"from_id_ensembl_id\", \"from_id_official_gene_symbol\", \"from_symbol_ensembl_id\", \"from_symbol_official_gene_symbol\", \"gene_id\", \"gene_symbol\"], inplace=True)\n",
    "\n",
    "    ## Drop anything that is missing both ensembl_id and official_symbol. Also drop any duplicates\n",
    "    dff.dropna(subset=[\"ensembl_id\", \"official_symbol\"], how=\"all\", inplace=True)\n",
    "    \n",
    "    ## Drop Duplicates\n",
    "    dff.drop_duplicates(inplace=True)\n",
    "    dff.drop_duplicates(subset=[\"ensembl_id\", \"official_symbol\"], inplace=True)\n",
    "\n",
    "    \n",
    "    ## Make ensembl id and official symbol the first two columns \n",
    "    dff = dff[dff.columns[-2:].tolist() + dff.columns[:-2].tolist()].copy()\n",
    "\n",
    "    \n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15323d60-e44b-4037-8712-1f4b3551b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file names: miller_et_al_parietal_white_matter.csv \n",
      "\n",
      "Opening file names: das_et_al_plaque_vs_control.csv \n",
      "\n",
      "Opening file names: king_et_al_BA17_synaptoneurosome.csv \n",
      "\n",
      "Opening file names: miller_et_al_temporal_cortex.csv \n",
      "\n",
      "Opening file names: marques-coelho_et_al.csv \n",
      "\n",
      "Opening file names: das_et_al_tangle_vs_control.csv \n",
      "\n",
      "Opening file names: king_et_al_BA17_total_brain_homogenate.csv \n",
      "\n",
      "Opening file names: fischer_et_al.csv \n",
      "\n",
      "Opening file names: felsky_et_al.csv \n",
      "\n",
      "Opening file names: miller_et_al_parietal_cortex.csv \n",
      "\n",
      "Opening file names: miller_et_al_hippocampus.csv \n",
      "\n",
      "Opening file names: das_et_al_peri-plaque_vs_control.csv \n",
      "\n",
      "Opening file names: van_rooij_et_al.csv \n",
      "\n",
      "Opening file names: das_et_al_distant_vs_control.csv \n",
      "\n",
      "Opening file names: king_et_al_BA20_synaptoneurosome.csv \n",
      "\n",
      "Opening file names: king_et_al_BA20_total_brain_homogenate.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = '../../data/raw_data/meta-analysis/'\n",
    "\n",
    "# List to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        ## Print filename for records\n",
    "        print(\"Opening file names:\", filename,\"\\n\")\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        ## Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        ## Append the dataframe to the list\n",
    "        dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "897500bc-eb95-4226-97c6-421eae3a2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix column names manually\n",
    "\n",
    "dataframes[0].columns = ['gene_symbol', 'AD vs Control: Parietal White Matter - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: White Matter - SVA P-value -  RIN corrected']\n",
    "      \n",
    "dataframes[1].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "      \n",
    "dataframes[2].columns = ['gene_id', 'gene_symbol', 'BA17_SNp_HA_vs_AD.l2fc', 'BA17_SNp_HA_vs_AD.pval',\n",
    "       'BA17_SNp_HA_vs_AD.padj', 'BA17_SNp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
    "      \n",
    "dataframes[3].columns = ['gene_symbol', 'AD vs Control: Temporal Cortex - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: Temporal Cortex - SVA P-value -  RIN corrected',\n",
    "       'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n",
    "\n",
    "dataframes[4].columns = ['transcript_name', 'dataset', 'gene_id', 'gene_symbol', 'logFC', 'gene.padj',\n",
    "       'transcript.log2FC', 'transcript.padj', 'gene_biotype', 'iso_biotype',\n",
    "       'dtu.dIF', 'dtu.gene.padj', 'dtu.isoform.padj', 'dtu.ofdr.gene',\n",
    "       'dtu.ofdr.transcript', 'threshDT', 'threshG']\n",
    "\n",
    "dataframes[5].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "      \n",
    "dataframes[6].columns = ['gene_id', 'gene_symbol', 'BA17_THp_HA_vs_AD.l2fc', 'BA17_THp_HA_vs_AD.pval',\n",
    "       'BA17_THp_HA_vs_AD.padj', 'BA17_THp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
    "      \n",
    "dataframes[7].columns = ['gene_id', 'entrez_id', 'gene_symbol', 'logFC', 'AveExpr', 't', 'P.Value',\n",
    "       'adj.P.Val']\n",
    "      \n",
    "dataframes[8].columns = ['gene_id', 'gene_symbol', 'logFC', 'AveExpr', 't', 'P.Value', 'adj.P.Val', 'B',\n",
    "       'se', 'chr', 'N']\n",
    "      \n",
    "dataframes[9].columns = ['gene_symbol', 'AD vs Control: Parietal Cortex - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: Parietal Cortex - SVA P-value -  RIN corrected']\n",
    "      \n",
    "dataframes[10].columns = ['gene_symbol', 'AD vs Control: Hippocampus - Log2(fold change) - RIN Corrected',\n",
    "       'AD vs Control: Hippocampus - SVA P-value -  RIN corrected']\n",
    "      \n",
    "dataframes[11].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "      \n",
    "dataframes[12].columns = ['gene_symbol', 'logFC', 'logCPM', 'PValue', 'FDR', 'UP/DOWN', 'DE Score']\n",
    "\n",
    "dataframes[13].columns = ['gene_id', 'gene_symbol', 'logFC', 'CI.L', 'CI.R', 'AveExpr', 't',\n",
    "       'P.Value', 'adj.P.Val', 'B']\n",
    "\n",
    "dataframes[14].columns = ['gene_id', 'gene_symbol', 'BA20_SNp_HA_vs_AD.l2fc', 'BA20_SNp_HA_vs_AD.pval',\n",
    "       'BA20_SNp_HA_vs_AD.padj', 'BA20_SNp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
    "\n",
    "dataframes[15].columns = ['gene_id', 'gene_symbol', 'BA20_THp_HA_vs_AD.l2fc', 'BA20_THp_HA_vs_AD.pval',\n",
    "       'BA20_THp_HA_vs_AD.padj', 'BA20_THp_HA_vs_AD.raw_l2fc', 'Unnamed: 6',\n",
    "       'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcf4bda7-912e-4ac7-9515-c1e113b60c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove unnamed columns\n",
    "\n",
    "for df in dataframes:\n",
    "    df.drop(columns=[col for col in df.columns if col.startswith('Unnamed:')], inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382669e9-c8c2-4a76-b5dc-9ca63fff9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keep the relevant columns\n",
    "\n",
    "dataframes[0] = dataframes[0][['gene_symbol', 'AD vs Control: Parietal White Matter - Log2(fold change) - RIN Corrected',\n",
    "                'AD vs Control: White Matter - SVA P-value -  RIN corrected']].copy()\n",
    "dataframes[0].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[1] = dataframes[1][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[1].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[2] = dataframes[2][['gene_id', 'gene_symbol', 'BA17_SNp_HA_vs_AD.l2fc', 'BA17_SNp_HA_vs_AD.pval']].copy()\n",
    "dataframes[2].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[3] = dataframes[3][['gene_symbol', 'AD vs Control: Temporal Cortex - Log2(fold change) - RIN Corrected',\n",
    "                               'AD vs Control: Temporal Cortex - SVA P-value -  RIN corrected']]\n",
    "dataframes[3].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[4] = dataframes[4][['dataset', 'gene_id', 'gene_symbol', 'logFC', 'gene.padj']].copy()\n",
    "dataframes[4].columns = ['dataset', 'gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[5] = dataframes[5][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[5].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[6] = dataframes[6][['gene_id', 'gene_symbol', 'BA17_THp_HA_vs_AD.l2fc', 'BA17_THp_HA_vs_AD.pval']].copy()\n",
    "dataframes[6].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[7] = dataframes[7][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[7].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[8] = dataframes[8][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[8].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[9] = dataframes[9][['gene_symbol', 'AD vs Control: Parietal Cortex - Log2(fold change) - RIN Corrected',\n",
    "               'AD vs Control: Parietal Cortex - SVA P-value -  RIN corrected']].copy()\n",
    "dataframes[9].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[10] = dataframes[10][['gene_symbol', 'AD vs Control: Hippocampus - Log2(fold change) - RIN Corrected',\n",
    "                'AD vs Control: Hippocampus - SVA P-value -  RIN corrected']].copy()\n",
    "dataframes[10].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[11] = dataframes[11][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[11].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[12] = dataframes[12][['gene_symbol', 'logFC',  'PValue']].copy()\n",
    "dataframes[12].columns = ['gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[13] = dataframes[13][['gene_id', 'gene_symbol', 'logFC', 'P.Value']].copy()\n",
    "dataframes[13].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[14] = dataframes[14][['gene_id', 'gene_symbol', 'BA20_SNp_HA_vs_AD.l2fc', 'BA20_SNp_HA_vs_AD.pval']].copy()\n",
    "dataframes[14].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]\n",
    "\n",
    "dataframes[15] = dataframes[15][['gene_id', 'gene_symbol', 'BA20_THp_HA_vs_AD.l2fc', 'BA20_THp_HA_vs_AD.pval']].copy()\n",
    "dataframes[15].columns = ['gene_id', 'gene_symbol', \"log2_fold_change\", \"p_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42de0f92-8952-4e53-9305-de29d55361a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pop the main dataframe and further process it\n",
    "marques_coelho = dataframes.pop(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c72e2bb-06ca-4d5c-b14a-86eb436a6681",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate different datasets in marques_coelho study.\n",
    "marques_coelho_MAYO_temporal = marques_coelho.loc[marques_coelho[\"dataset\"] == \"MAYO\"].copy()\n",
    "marques_coelho_MSBB_BM10_temporal = marques_coelho.loc[marques_coelho[\"dataset\"] == \"MSBB BM10\"].copy()\n",
    "marques_coelho_MSBB_BM22_frontal = marques_coelho.loc[marques_coelho[\"dataset\"] == \"MSBB BM22\"].copy()\n",
    "marques_coelho_MSBB_BM36_frontal = marques_coelho.loc[marques_coelho[\"dataset\"] == \"MSBB BM36\"].copy()\n",
    "marques_coelho_MSBB_BM44_temporal = marques_coelho.loc[marques_coelho[\"dataset\"] == \"MSBB BM44\"].copy()\n",
    "marques_coelho_ROSMAP_frontal = marques_coelho.loc[marques_coelho[\"dataset\"] == \"ROSMAP\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab743b0c-6130-4858-b794-6bc2b9072ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create list with dataframes for marques-coelho\n",
    "marques_coelho_dataframes = [marques_coelho_MAYO_temporal, marques_coelho_MSBB_BM10_temporal, marques_coelho_MSBB_BM22_frontal,\n",
    "                             marques_coelho_MSBB_BM36_frontal, marques_coelho_MSBB_BM44_temporal, marques_coelho_ROSMAP_frontal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a85ff416-d366-4e11-a0b4-49bef9d315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## STANDARDIZE NON MARQUES-COELHO RESULTS\n",
    "\n",
    "## Initialize counter\n",
    "i=0\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "    \n",
    "    ## Standardize missing values\n",
    "    df = df.replace({np.nan: pd.NA, None: pd.NA})\n",
    "    \n",
    "    if \"gene_id\" in df.columns:\n",
    "        ## Take out . from ensembl ids\n",
    "        df[\"gene_id\"] = df[\"gene_id\"].str.split(\".\", expand=True)[0]\n",
    "        ## Set gene ids that are not ensembl IDs to NA\n",
    "        df['gene_id'] = df['gene_id'].apply(lambda x: x if pd.isna(x) or str(x).startswith('ENS') else pd.NA)\n",
    "\n",
    "    # Check if 'gene_symbol' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_symbol' not in df.columns:\n",
    "        df['gene_symbol'] = df['gene_id'].copy()\n",
    "\n",
    "    # Check if 'ensembl_id' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_id' not in df.columns:\n",
    "        df['gene_id'] = df['gene_symbol'].copy()\n",
    "\n",
    "    # Ensure 'ensembl_id' is the first column and 'gene_symbol' is the second column\n",
    "    columns = ['gene_id', 'gene_symbol'] + [col for col in df.columns if col not in ['gene_id', 'gene_symbol']]\n",
    "    df = df[columns].copy()\n",
    "    dataframes[i] = df\n",
    "\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52960330-f1bc-4db7-8c34-92421c63531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO SAME THING FOR MARQUES COELHO DATAFRAME\n",
    "\n",
    "## Initialize counter\n",
    "i=0\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in marques_coelho_dataframes:\n",
    "    \n",
    "    ## Drop dataset column\n",
    "    df.drop(columns=\"dataset\", inplace=True)\n",
    "    \n",
    "    ## Standardize missing values\n",
    "    df = df.replace({np.nan: pd.NA, None: pd.NA})\n",
    "    \n",
    "    if \"gene_id\" in df.columns:\n",
    "        ## Take out . from ensembl ids\n",
    "        df[\"gene_id\"] = df[\"gene_id\"].str.split(\".\", expand=True)[0]\n",
    "        ## Set gene ids that are not ensembl IDs to NA\n",
    "        df['gene_id'] = df['gene_id'].apply(lambda x: x if pd.isna(x) or str(x).startswith('ENS') else pd.NA)\n",
    "\n",
    "    # Check if 'gene_symbol' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_symbol' not in df.columns:\n",
    "        df['gene_symbol'] = df['gene_id'].copy()\n",
    "\n",
    "    # Check if 'ensembl_id' column is missing and add it filled with NAs if necessary\n",
    "    if 'gene_id' not in df.columns:\n",
    "        df['gene_id'] = df['gene_symbol'].copy()\n",
    "\n",
    "    # Ensure 'ensembl_id' is the first column and 'gene_symbol' is the second column\n",
    "    columns = ['gene_id', 'gene_symbol'] + [col for col in df.columns if col not in ['gene_id', 'gene_symbol']]\n",
    "    df = df[columns].copy()\n",
    "    marques_coelho_dataframes[i] = df\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54f6e346-b51c-4fb7-b957-c5c181ddcc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now standardize gene_symbol and gene_id for all the dataframes that are MARQUES-COELHO\n",
    "\n",
    "## Initialize counter\n",
    "i=0\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in marques_coelho_dataframes:\n",
    "\n",
    "    print(i)\n",
    "    ## Create master dataframe\n",
    "    master_df = unify_gene_ids_and_symbols(df)\n",
    "\n",
    "    ## Create column that is the official gene symbol, unless that is NA, then make it the ensembl_id\n",
    "    \n",
    "    # Check if 'gene_symbol' column is missing and add it filled with NAs if necessary\n",
    "    if 'official_symbol' not in master_df.columns:\n",
    "        master_df['official_symbol'] = \"NA_symbol\"\n",
    "\n",
    "    # Check if 'ensembl_id' column is missing and add it filled with NAs if necessary\n",
    "    if 'ensembl_id' not in master_df.columns:\n",
    "        master_df['ensembl_id'] = \"NA_id\"\n",
    "    \n",
    "    master_df['gene_name'] = master_df['official_symbol'].copy() + \"|\" + master_df['ensembl_id'].copy()\n",
    "\n",
    "    ## Make it the first column\n",
    "    master_df = master_df[master_df.columns[-1:].tolist() + master_df.columns[:-1].tolist()]\n",
    "\n",
    "    marques_coelho_dataframes[i] = master_df\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe7c7b-8336-4563-837d-85d9af3e5baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get output file names FOR MARQUES-COELHO\n",
    "output_names = [\"marques_coelho_MAYO_temporal.tsv\", \n",
    "                \"marques_coelho_MSBB_BM10_temporal.tsv\",\n",
    "                \"marques_coelho_MSBB_BM22_frontal.tsv\", \n",
    "                \"marques_coelho_MSBB_BM36_frontal.tsv\",\n",
    "                \"marques_coelho_MSBB_BM44_temporal.tsv\", \n",
    "                \"marques_coelho_ROSMAP_frontal.tsv\"]\n",
    "\n",
    "sample_sizes = [160, 233, 238, 232, 227, 403]\n",
    "\n",
    "\n",
    "## Now add information and save\n",
    "\n",
    "## Initialize counter and output directory\n",
    "i=0\n",
    "output_dir = \"../../data/processed_data/meta-analysis/meta-analysis_input_marques-coelho/\"\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "\n",
    "    marques_coelho_dataframes[i] = marques_coelho_dataframes[i][[\"gene_name\", \"log2_fold_change\", \"p_value\"]].copy()\n",
    "\n",
    "    ## Add sample sizes\n",
    "    marques_coelho_dataframes[i][\"sample_size\"] = sample_sizes[i]\n",
    "    marques_coelho_dataframes[i][\"ref_allele\"] = \"Control\"\n",
    "    marques_coelho_dataframes[i][\"non_ref_allele\"] = \"AD\"\n",
    "\n",
    "    ## Create output path\n",
    "    output_path = output_dir + output_names[i]\n",
    "\n",
    "    marques_coelho_dataframes[i].to_csv(output_path, index=False, sep=\"\\t\")\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df3566a-5b99-4695-8628-1cbbed1e5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3 input query terms found dup hits:\t[('ENSG00000230373', 2), ('ENSG00000268674', 3), ('ENSG00000284926', 2)]\n",
      "299 input query terms found no hit:\t['ENSG00000130489', 'ENSG00000182230', 'ENSG00000241978', 'ENSG00000285258', 'ENSG00000168078', 'ENS\n",
      "8346 input query terms found dup hits:\t[('M6PR', 3), ('FKBP4', 2), ('SEMA3F', 2), ('CFTR', 10), ('CYP51A1', 2), ('SLC7A2', 2), ('PDK4', 3),\n",
      "5266 input query terms found no hit:\t['AC021097.2', 'AC008013.1', 'AL078645.2', 'AC011473.4', 'AC139677.2', 'AL391994.1', 'AL138847.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7 input query terms found dup hits:\t[('ENSG00000230373', 2), ('ENSG00000267635', 2), ('ENSG00000268674', 3), ('ENSG00000277176', 5), ('E\n",
      "334 input query terms found no hit:\t['ENSG00000130489', 'ENSG00000182230', 'ENSG00000241978', 'ENSG00000285258', 'ENSG00000168078', 'ENS\n",
      "9579 input query terms found dup hits:\t[('M6PR', 3), ('FKBP4', 2), ('SEMA3F', 2), ('CFTR', 10), ('CYP51A1', 2), ('SLC7A2', 2), ('PDK4', 3),\n",
      "7290 input query terms found no hit:\t['AC008033.1', 'AC021097.2', 'AC008013.1', 'AL078645.2', 'AC011473.4', 'AC139677.2', 'AL391994.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6 input query terms found dup hits:\t[('ENSG00000230373', 2), ('ENSG00000267635', 2), ('ENSG00000268674', 3), ('ENSG00000277176', 5), ('E\n",
      "332 input query terms found no hit:\t['ENSG00000130489', 'ENSG00000182230', 'ENSG00000241978', 'ENSG00000285258', 'ENSG00000168078', 'ENS\n",
      "9492 input query terms found dup hits:\t[('M6PR', 3), ('FKBP4', 2), ('SEMA3F', 2), ('CFTR', 10), ('CYP51A1', 2), ('SLC7A2', 2), ('PDK4', 3),\n",
      "7194 input query terms found no hit:\t['AC008033.1', 'AC021097.2', 'AC008013.1', 'AL078645.2', 'AC011473.4', 'AC139677.2', 'AL391994.1', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f4430643820>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Now standardize gene_symbol and gene_id for all the dataframes that are NON MARQUES-COELHO\n",
    "\n",
    "## Initialize counter\n",
    "i=0\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "\n",
    "    print(i)\n",
    "    ## Create master dataframe\n",
    "    master_df = unify_gene_ids_and_symbols(df)\n",
    "\n",
    "    ## Create column that is the official gene symbol, unless that is NA, then make it the ensembl_id\n",
    "    \n",
    "    # Check if 'gene_symbol' column is missing and add it filled with NAs if necessary\n",
    "    if 'official_symbol' not in master_df.columns:\n",
    "        master_df['official_symbol'] = \"NA_symbol\"\n",
    "\n",
    "    # Check if 'ensembl_id' column is missing and add it filled with NAs if necessary\n",
    "    if 'ensembl_id' not in master_df.columns:\n",
    "        master_df['ensembl_id'] = \"NA_id\"\n",
    "    \n",
    "    master_df['gene_name'] = master_df['official_symbol'].copy() + \"|\" + master_df['ensembl_id'].copy()\n",
    "\n",
    "    ## Make it the first column\n",
    "    master_df = master_df[master_df.columns[-1:].tolist() + master_df.columns[:-1].tolist()]\n",
    "\n",
    "    dataframes[i] = master_df\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a79d6a-79fd-43ca-87bf-5616f784f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get output file names for NON MARQUES-COELHO\n",
    "output_names = [\"miller_et_al_parietal_white_matter_ad_vs_control_RIN_corrected_processed.tsv\", \n",
    "                \"das_et_al_superior_temporal_gyrus_ad_plaque_ad_vs_control.tsv\",\n",
    "                \"king_et_al_BA17_visual_cortex_synaptoneurosome_ad_vs_ha.tsv\", \n",
    "                \"miller_et_al_temporal_cortex_ad_vs_control_RIN_corrected_processed.tsv\",\n",
    "                \"das_et_al_superior_temporal_gyrus_ad_tangle_vs_control.tsv\", \n",
    "                \"king_et_al_BA17_visual_cortex_total_brain_homogenate_ad_vs_ha.tsv\",\n",
    "                \"fischer_et_al_prefrontal_cortex_ad_vs_control.tsv\", \n",
    "                \"felsky_et_al_temporal_cortex_ad_vs_control.tsv\", \n",
    "                \"miller_et_al_parietal_cortex_ad_vs_control_RIN_corrected_processed.tsv\",\n",
    "                \"miller_et_al_hippocampus_ad_vs_control_RIN_corrected_processed.tsv\", \n",
    "                \"das_et_al_superior_temporal_gyrus_ad_peri-plaque_vs_control.tsv\",\n",
    "                \"van_rooij_et_al_hippocampus_ad_vs_control.tsv\", \n",
    "                \"das_et_al_superior_temporal_gyrus_ad_distant_vs_control.tsv\",\n",
    "                \"king_et_al_BA20_temporal_cortex_synaptoneurosome_ad_vs_ha.tsv\",\n",
    "                \"king_et_al_BA20_temporal_cortex_total_brain_homogenate_ad_vs_ha.tsv\"]\n",
    "\n",
    "## Get sample sizes\n",
    "sample_sizes = [106, 18, 31, 106, 18 ,31, 29, 39, 106, 106, 18, 28, 18, 31 ,31]\n",
    "\n",
    "\n",
    "## Now add information and save\n",
    "\n",
    "## Initialize counter and output directory\n",
    "i=0\n",
    "output_dir = \"../../data/processed_data/meta-analysis/meta-analysis_input/\"\n",
    "\n",
    "## Loop through dataframes\n",
    "for df in dataframes:\n",
    "\n",
    "    dataframes[i] = dataframes[i][[\"gene_name\", \"log2_fold_change\", \"p_value\"]].copy()\n",
    "\n",
    "    ## Add sample sizes\n",
    "    dataframes[i][\"sample_size\"] = sample_sizes[i]\n",
    "    dataframes[i][\"ref_allele\"] = \"Control\"\n",
    "    dataframes[i][\"non_ref_allele\"] = \"AD\"\n",
    "\n",
    "    ## Create output path\n",
    "    output_path = output_dir + output_names[i]\n",
    "\n",
    "    dataframes[i].to_csv(output_path, index=False, sep=\"\\t\")\n",
    "\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
